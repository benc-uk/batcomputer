#
# Trigger job in DataBricks and pass parameters
# Ben C, 2019
#
# TEMPLATE FILE USED BY OTHER PIPELINES
#

#
# Make sure we're using Python 3
#
steps:
- task: UsePythonVersion@0
  displayName: 'Use Python 3.6'
  inputs:
    versionSpec: 3.6

#
# The DataBricks CLI needs installing
# And create the connection config file
#
- script: |
    pip3 install databricks-cli 
    echo "[DEFAULT]" >> ~/.databrickscfg
    echo "host = $(databricks-host)" >> ~/.databrickscfg
    echo "token = $(databricks-token)" >> ~/.databrickscfg
  displayName: 'Setup DataBricks CLI'

#
# Import the workbook from git into DataBricks
# This can be considered "promoting" it from local dev to real system for CI
#
- script: |
    databricks workspace import notebooks/$(notebook-name).py /live/$(notebook-name) -l python -o
  displayName: 'Import notebook from git into live'

#
# Then kick off running the job, step will wait for job to complete ...
# Uses some bash scripting and jq to make task slightly more fancy
#
- script: |
    jobid=`databricks jobs list --output JSON|jq '.jobs[] | select(.settings.name == "$(job-name)").job_id'`
    runid=`databricks jobs run-now --job-id $jobid --notebook-params '$(job-params)' | jq .run_id`
    echo "***** Job $(job-name) job-id:$jobid started run with run-id:$runid *****"
    while [ : ]
    do
      echo "Sleeping for 20 seconds..."
      sleep 20s
      state=`databricks runs list --job-id $jobid --output JSON | jq -r --argjson rid "$runid" '.runs[] | select(.run_id == $rid).state.life_cycle_state'`
      echo "Status of job-id:$jobid, run-id:$runid is $state"
      if [[ "$state" == 'TERMINATED' ]]; then
        break
      fi
    done
    databricks runs get --run-id $runid
    result=`databricks runs get --run-id $runid | jq -r .state.result_state`
    if [[ "$result" != 'SUCCESS' ]]; then
      echo "ERROR! Job run result was not SUCCESS"
      exit 125
    fi
  displayName: 'Run DataBricks job and wait for completion'
  failOnStderr: true
